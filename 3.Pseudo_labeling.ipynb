{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from os.path import join as opj\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test data labels using first pass VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are using the model output from VGG15 First Pass in order to predict the labels on the unlabeled 'test.json' dataset provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_validation = pd.read_json('test.json')\n",
    "Valid_75 = pickle.load(open('HH_HV_Com_validation_75.p', 'rb'))\n",
    "vgg_Pseudo_dec5 = load_model('models/vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict using first pass VGG16 model\n",
    "yproba_vgg_aug_params_dec5_Pseudo = vgg_Pseudo_dec5.predict(Valid_75)[:, 1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create csv file for kaggle submission\n",
    "def output_submission(yproba, df_validation):\n",
    "    submission = pd.DataFrame(yproba)\n",
    "    df_submission = pd.concat([pd.DataFrame(df_validation['id']), submission], axis=1)\n",
    "    df_submission = df_submission.rename(columns={0: 'is_iceberg'})\n",
    "    df_submission.to_csv('First_Pass_VGG16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission(yproba_vgg_aug_params_dec5_Pseudo, df_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pseudo labeled for input to VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method of Pseudo labeling used from following paper on machine learning for SAR images: <br> Gao, F., Yue, Z., Wang, J., Sun, J., Yang, E., & Zhou, H. A Novel Active Semi-Supervised Convolutional Neural Network Algorithm for SAR Image Recognition. Computational Intelligence and Neuroscience. <br>\n",
    "\n",
    "The pseudo labeling technique is to use yproba for each observation and select your most confident predictions then merge this dataset back in with the original labeled dataset. In this way you're able to expand the size of the training set, for retraining the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function taking in the num images of each class, and returning the pseudo labeled dataset with that many additional images\n",
    "def Pseudo_Label(num_images):\n",
    "    # Load predicted labels from previous VGG16 data\n",
    "    validation_labels_vgg16 = pd.read_csv('First_Pass_VGG16.csv')\n",
    "    validation_vgg16 = []\n",
    "    validation_labels_vgg16 = validation_labels_vgg16.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "    # Merge probability labels with image data\n",
    "    for i, entry in enumerate(validation_labels_vgg16):\n",
    "        validation_vgg16.append([entry, Valid_75[i]])\n",
    "\n",
    "    # Sort by probability (i.e. confidence), select 1600 ship labels and icebergs labels with highest confidence\n",
    "    first_item = itemgetter(0)\n",
    "    validation_sorted_vgg16 = sorted(validation_vgg16, key = first_item)\n",
    "    validation_select_vgg16 = validation_sorted_vgg16[:num_images] + validation_sorted_vgg16[-num_images:]\n",
    "\n",
    "    # Force labels to be 0 or 1\n",
    "    labels_vgg16 = []\n",
    "    for x in validation_select_vgg16:\n",
    "        if x[0] > .5:\n",
    "            labels_vgg16.append(1.0)\n",
    "        else:\n",
    "            labels_vgg16.append(0.0)\n",
    "\n",
    "    # Seperate X and Y validation datasets\n",
    "    y_valid_vgg16 = np.array(labels_vgg16)\n",
    "    HH_HV_Com_Valid_75_vgg16 = [x[1] for x in validation_select_vgg16]\n",
    "    HH_HV_Com_Valid_75_vgg16 = np.array(HH_HV_Com_Valid_75_vgg16)\n",
    "\n",
    "    # Load training set and merge with Pseudo labeled set\n",
    "    HH_HV_Com_75 = pickle.load(open('HH_HV_Com_75.p', 'rb'))\n",
    "    df_train = pd.read_json('train.json')\n",
    "    y = np.array(df_train.is_iceberg)\n",
    "    HH_HV_Com_Pseudo_vgg16 = np.concatenate((HH_HV_Com_75, HH_HV_Com_Valid_75_vgg16), axis=0)\n",
    "    y_Pseudo_vgg16 = np.concatenate((y, y_valid_vgg16), axis=0)\n",
    "    \n",
    "    with open('test_train/HH_HV_Com_Pseudo_vgg16_Dec5.p', 'wb') as handle:\n",
    "        pickle.dump(HH_HV_Com_Pseudo_vgg16, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('test_train/y_Pseudo_vgg16_Dec5.p', 'wb') as handle:\n",
    "        pickle.dump(y_Pseudo_vgg16, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes out Pseudo labeled dataset\n",
    "Pseudo_Label(1600)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
